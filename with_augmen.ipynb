{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_loaded = True\n",
    "already_augmented = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 2489\n",
      "Image dimensions: 125 x 94 x 3\n",
      "n_features: 35250\n",
      "n_classes: 43\n"
     ]
    }
   ],
   "source": [
    "if not already_loaded:\n",
    "    \n",
    "    # Load the LFW dataset in color with original image size\n",
    "    lfw_people = fetch_lfw_people(color=True, resize=None, min_faces_per_person=20)\n",
    "\n",
    "    n_samples, h, w, c = lfw_people.images.shape\n",
    "\n",
    "    X = lfw_people.data\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    y = lfw_people.target\n",
    "    target_names = lfw_people.target_names\n",
    "    n_classes = target_names.shape[0]\n",
    "\n",
    "    print(\"Total dataset size:\")\n",
    "    print(\"n_samples: %d\" % n_samples)\n",
    "    print(f\"Image dimensions: {h} x {w} x {c}\")\n",
    "    print(\"n_features: %d\" % n_features)\n",
    "    print(\"n_classes: %d\" % n_classes)\n",
    "\n",
    "    dump(lfw_people, 'lfw_dataset.joblib')\n",
    "\n",
    "else:\n",
    "    # Load the dataset from the saved file\n",
    "    lfw_people = load('lfw_dataset.joblib')\n",
    "\n",
    "    n_samples, h, w, c = lfw_people.images.shape\n",
    "\n",
    "    X = lfw_people.data\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    y = lfw_people.target\n",
    "    target_names = lfw_people.target_names\n",
    "    n_classes = target_names.shape[0]\n",
    "\n",
    "    print(\"Total dataset size:\")\n",
    "    print(\"n_samples: %d\" % n_samples)\n",
    "    print(f\"Image dimensions: {h} x {w} x {c}\")\n",
    "    print(\"n_features: %d\" % n_features)\n",
    "    print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique classes (person IDs)\n",
    "unique_classes = np.unique(y_train)\n",
    "\n",
    "# Create a dictionary to hold separated classes\n",
    "class_images = {class_id: [] for class_id in unique_classes}\n",
    "images_name = {}\n",
    "\n",
    "# Separate images into respective classes\n",
    "for idx, label in enumerate(y_train):\n",
    "    class_images[label].append(X_train[idx])\n",
    "    images_name[label] = lfw_people.target_names[label]\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "for class_id in class_images:\n",
    "    class_images[class_id] = np.array(class_images[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 11, George W Bush: 371 images\n",
      "Class 7, Colin Powell: 165 images\n",
      "Class 40, Tony Blair: 100 images\n",
      "Class 9, Donald Rumsfeld: 85 images\n",
      "Class 12, Gerhard Schroeder: 76 images\n",
      "Class 4, Ariel Sharon: 53 images\n",
      "Class 17, Hugo Chavez: 50 images\n",
      "Class 26, Junichiro Koizumi: 42 images\n",
      "Class 21, Jean Chretien: 38 images\n",
      "Class 20, Jacques Chirac: 37 images\n",
      "Class 24, John Ashcroft: 37 images\n",
      "Class 36, Serena Williams: 36 images\n",
      "Class 42, Vladimir Putin: 34 images\n",
      "Class 13, Gloria Macapagal Arroyo: 31 images\n",
      "Class 23, Jennifer Capriati: 30 images\n",
      "Class 28, Laura Bush: 29 images\n",
      "Class 30, Lleyton Hewitt: 29 images\n",
      "Class 0, Alejandro Toledo: 27 images\n",
      "Class 16, Hans Blix: 27 images\n",
      "Class 3, Andre Agassi: 25 images\n",
      "Class 1, Alvaro Uribe: 24 images\n",
      "Class 27, Kofi Annan: 23 images\n",
      "Class 31, Megawati Sukarnoputri: 23 images\n",
      "Class 39, Tom Ridge: 23 images\n",
      "Class 41, Vicente Fox: 23 images\n",
      "Class 8, David Beckham: 22 images\n",
      "Class 6, Bill Clinton: 20 images\n",
      "Class 19, Jack Straw: 19 images\n",
      "Class 25, Juan Carlos Ferrero: 19 images\n",
      "Class 14, Gray Davis: 18 images\n",
      "Class 34, Rudolph Giuliani: 18 images\n",
      "Class 5, Atal Bihari Vajpayee: 17 images\n",
      "Class 38, Tom Daschle: 17 images\n",
      "Class 10, George Robertson: 16 images\n",
      "Class 15, Hamid Karzai: 16 images\n",
      "Class 29, Lindsay Davenport: 16 images\n",
      "Class 33, Pete Sampras: 16 images\n",
      "Class 35, Saddam Hussein: 16 images\n",
      "Class 37, Tiger Woods: 16 images\n",
      "Class 2, Amelie Mauresmo: 15 images\n",
      "Class 22, Jennifer Aniston: 15 images\n",
      "Class 18, Igor Ivanov: 14 images\n",
      "Class 32, Michael Bloomberg: 14 images\n"
     ]
    }
   ],
   "source": [
    "class_images_sorted = {class_id: images for class_id, images in sorted(class_images.items(), key=lambda x: len(x[1]), reverse=True)}\n",
    "\n",
    "for class_id, images in class_images_sorted.items():\n",
    "    print(f\"Class {class_id}, {lfw_people.target_names[class_id]}: {images.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_data(class_images_sorted):\n",
    "\n",
    "    # Define Albumentations transformations\n",
    "    transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=(-20, 20), p=0.5),  # Random rotation between -30 and 30 degrees\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "        A.Blur(blur_limit=2, p=0.5),\n",
    "    ])\n",
    "\n",
    "    # Set the desired number of images per class\n",
    "    desired_num_images = 200\n",
    "\n",
    "    # Create a dictionary to hold augmented images\n",
    "    augmented_class_images = {}\n",
    "\n",
    "    # Loop through sorted_class_images\n",
    "    for class_id, images in class_images_sorted.items():\n",
    "        num_images = images.shape[0]\n",
    "        if num_images >= desired_num_images:\n",
    "            # If the class has more than or equal to 200 images, randomly select 200 images\n",
    "            selected_indices = np.random.choice(num_images, size=desired_num_images, replace=False)\n",
    "            selected_images = images[selected_indices]\n",
    "            augmented_class_images[class_id] = selected_images\n",
    "        else:\n",
    "            # If the class has fewer than 200 images, augment the existing images to reach 200\n",
    "            num_to_generate = desired_num_images - num_images\n",
    "            # Perform data augmentation\n",
    "            augmented_images = []\n",
    "            for i in range(num_to_generate):\n",
    "                # Flatten the 'images' array and randomly choose one image array\n",
    "                selected_image_idx = np.random.choice(images.shape[0])\n",
    "                selected_image = images[selected_image_idx]\n",
    "                \n",
    "                # Reshape the selected image to its original shape\n",
    "                selected_image = selected_image.reshape((h, w, c))\n",
    "                # Apply Albumentations transformations\n",
    "                augmented = transform(image=selected_image)\n",
    "                augmented_image = augmented[\"image\"]\n",
    "                \n",
    "                # Flatten the augmented image\n",
    "                flattened_augmented_image = augmented_image.flatten()\n",
    "                \n",
    "                # Append the flattened image to the list\n",
    "                augmented_images.append(flattened_augmented_image)\n",
    "                \n",
    "            # Concatenate the original images and augmented images\n",
    "            augmented_images = np.array(augmented_images)\n",
    "            augmented_class_images[class_id] = np.concatenate((images, augmented_images), axis=0)\n",
    "\n",
    "    return augmented_class_images\n",
    "\n",
    "    # Now augmented_class_images dictionary contains all images separated by their respective classes, \n",
    "    # with each class having 200 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 11, George W Bush: 200 images\n",
      "Class 7, Colin Powell: 200 images\n",
      "Class 40, Tony Blair: 200 images\n",
      "Class 9, Donald Rumsfeld: 200 images\n",
      "Class 12, Gerhard Schroeder: 200 images\n",
      "Class 4, Ariel Sharon: 200 images\n",
      "Class 17, Hugo Chavez: 200 images\n",
      "Class 26, Junichiro Koizumi: 200 images\n",
      "Class 21, Jean Chretien: 200 images\n",
      "Class 20, Jacques Chirac: 200 images\n",
      "Class 24, John Ashcroft: 200 images\n",
      "Class 36, Serena Williams: 200 images\n",
      "Class 42, Vladimir Putin: 200 images\n",
      "Class 13, Gloria Macapagal Arroyo: 200 images\n",
      "Class 23, Jennifer Capriati: 200 images\n",
      "Class 28, Laura Bush: 200 images\n",
      "Class 30, Lleyton Hewitt: 200 images\n",
      "Class 0, Alejandro Toledo: 200 images\n",
      "Class 16, Hans Blix: 200 images\n",
      "Class 3, Andre Agassi: 200 images\n",
      "Class 1, Alvaro Uribe: 200 images\n",
      "Class 27, Kofi Annan: 200 images\n",
      "Class 31, Megawati Sukarnoputri: 200 images\n",
      "Class 39, Tom Ridge: 200 images\n",
      "Class 41, Vicente Fox: 200 images\n",
      "Class 8, David Beckham: 200 images\n",
      "Class 6, Bill Clinton: 200 images\n",
      "Class 19, Jack Straw: 200 images\n",
      "Class 25, Juan Carlos Ferrero: 200 images\n",
      "Class 14, Gray Davis: 200 images\n",
      "Class 34, Rudolph Giuliani: 200 images\n",
      "Class 5, Atal Bihari Vajpayee: 200 images\n",
      "Class 38, Tom Daschle: 200 images\n",
      "Class 10, George Robertson: 200 images\n",
      "Class 15, Hamid Karzai: 200 images\n",
      "Class 29, Lindsay Davenport: 200 images\n",
      "Class 33, Pete Sampras: 200 images\n",
      "Class 35, Saddam Hussein: 200 images\n",
      "Class 37, Tiger Woods: 200 images\n",
      "Class 2, Amelie Mauresmo: 200 images\n",
      "Class 22, Jennifer Aniston: 200 images\n",
      "Class 18, Igor Ivanov: 200 images\n",
      "Class 32, Michael Bloomberg: 200 images\n"
     ]
    }
   ],
   "source": [
    "augmented_class_images = get_augmented_data(class_images_sorted)\n",
    "\n",
    "for class_id, images in augmented_class_images.items():\n",
    "    print(f\"Class {class_id}, {lfw_people.target_names[class_id]}: {images.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Storing Augmented Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
